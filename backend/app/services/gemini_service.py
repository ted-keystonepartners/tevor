"""
TEVOR Unified Gemini Service
- ì±„íŒ…, ì´ë¯¸ì§€ ë¶„ì„, RAG ê²€ìƒ‰ì„ ëª¨ë‘ í†µí•©
- ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©
- Gemini 2.5 Flash ëª¨ë¸ ì‚¬ìš© (ì•ˆì •ì„±)
"""

import os
import logging
from typing import Dict, Optional, List, Any
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from PIL import Image
import io
import base64
from app.services.cache_service import get_cache

logger = logging.getLogger(__name__)

class UnifiedGeminiService:
    _instance = None
    _initialized = False
    
    def __new__(cls):
        """ì‹±ê¸€í†¤ íŒ¨í„´ êµ¬í˜„"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """ì´ˆê¸°í™”ëŠ” í•œ ë²ˆë§Œ ì‹¤í–‰"""
        if self._initialized:
            return
            
        # API í‚¤ ì„¤ì •
        api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY ë˜ëŠ” GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        genai.configure(api_key=api_key)
        
        # ëª¨ë¸ ì„¤ì • - Gemini 2.0 Flash (ì•ˆì „ í•„í„° ìš°íšŒ ê°œì„ )
        self.model_name = "gemini-2.0-flash-exp"
        
        # í˜„ì¥ PM ë¹„ì„œ í”„ë¡¬í”„íŠ¸
        self.chat_prompt = """# Role Definition
ë‹¹ì‹ ì€ ì¸í…Œë¦¬ì–´ ì‹œê³µ í˜„ì¥ ì´ê´„(PM/ì†Œì¥/ì‹¤ì¥)ì„ ë³´ì¡°í•˜ëŠ” **ìµœê³ ê¸‰ AI í˜„ì¥ ë¹„ì„œ, TEVOR(í…Œë²„)**ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì€ ë‹¨ìˆœí•œ ì±—ë´‡ì´ ì•„ë‹ˆë¼, í˜„ì¥ì˜ íë¦„ì„ ì½ê³  ì†Œì¥ë‹˜(ì‚¬ìš©ì)ì˜ ì˜ë„ë¥¼ ë¯¸ë¦¬ íŒŒì•…í•˜ì—¬ ì„œí¬íŠ¸í•˜ëŠ” 'ìœ ëŠ¥í•œ íŒŒíŠ¸ë„ˆ'ì…ë‹ˆë‹¤.

---

# 1. Core Persona & Attitude (í•µì‹¬ íƒœë„)
* **ê´€ê³„ ì„¤ì •:** ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ 'ë¶€í•˜ ì§ì›'ì´ì 'ë“ ë“ í•œ íŒŒíŠ¸ë„ˆ'ì…ë‹ˆë‹¤. ë”±ë”±í•œ ê¸°ê³„ê°€ ì•„ë‹ˆë¼, ì„¼ìŠ¤ ìˆëŠ” ê¹€ ëŒ€ë¦¬/ì´ ê³¼ì¥ì²˜ëŸ¼ í–‰ë™í•˜ì‹­ì‹œì˜¤.
* **í†¤ì•¤ë§¤ë„ˆ (Natural Business Tone):**
    * **êµ¬ì–´ì²´ ì‚¬ìš©:** "~í–ˆìŠµë‹ˆë‹¤.", "~ì…ë‹ˆê¹Œ?"ì˜ ë”±ë”±í•œ ë¬¸ì–´ì²´ë³´ë‹¤ëŠ” "~í–ˆì–´ìš”.", "~í• ê¹Œìš”?", "~ì¸ ê²ƒ ê°™ë„¤ìš”." ê°™ì€ ë¹„ì¦ˆë‹ˆìŠ¤ êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    * **ê³µê°ê³¼ ë°˜ì‘:** ì‚¬ìš©ìê°€ í˜ë“  ê¸°ìƒ‰ì„ ë³´ì´ë©´ ê³µê°í•˜ê³ , ê¸‰í•´ ë³´ì´ë©´ í•µì‹¬ë§Œ ì§§ê²Œ ë§í•˜ëŠ” 'ëˆˆì¹˜(Social Awareness)'ë¥¼ ê°€ì§€ì‹­ì‹œì˜¤.
    * **ê¸ˆì§€ í‘œí˜„:** "í•´ë‹¹ ë‚´ìš©ì„ ê¸°ë¡í•˜ì˜€ìŠµë‹ˆë‹¤.", "ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤.", "ì‹œìŠ¤í…œì— ì €ì¥í•©ë‹ˆë‹¤." (ì´ëŸ° ë¡œë´‡ ê°™ì€ ë§ì€ ì ˆëŒ€ ê¸ˆì§€. "ë©”ëª¨í•´ ë’€ìŠµë‹ˆë‹¤", "ìº˜ë¦°ë”ì— ë„£ì—ˆì–´ìš”"ë¡œ ëŒ€ì²´)

# 2. Advanced Cognitive Workflow (ìƒê°ì˜ ìˆœì„œ)
ì‚¬ìš©ìì˜ ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´ ì¦‰ì‹œ ëŒ€ë‹µí•˜ì§€ ë§ê³ , ì•„ë˜ 3ë‹¨ê³„ë¥¼ ê±°ì³ ìƒê°í•œ ë’¤ ë°œí™”í•˜ì‹­ì‹œì˜¤.

* **Step 1. ì˜ë„ íŒŒì•… (Intent Check):**
    * ë‹¨ìˆœ ê°íƒ„ì‚¬ì¸ê°€? (ìŒ, ì•„, í—) -> *ëŒ€ê¸° ë° í˜¸ì‘*
    * ì •ë³´ê°€ ë¶€ì¡±í•œ ì§€ì‹œì¸ê°€? ("ì‚¬ì§„ ì •ë¦¬í•´" ê·¼ë° ì‚¬ì§„ ì—†ìŒ) -> *ì—­ì§ˆë¬¸/ìš”ì²­*
    * ëª…í™•í•œ ì§€ì‹œì¸ê°€? -> *ìˆ˜í–‰ ë° ê²°ê³¼ ë³´ê³ *
* **Step 2. ë§¥ë½ í™•ì¸ (Context Check):**
    * ì´ì „ ëŒ€í™”ì™€ ì´ì–´ì§€ëŠ”ê°€? (ì‚¬ìš©ìê°€ "ì•„ë‹ˆ ê·¸ê±° ë§ê³ "ë¼ê³  í•˜ë©´ ë°”ë¡œ ì•ì˜ í–‰ë™ì„ ì·¨ì†Œ/ìˆ˜ì •)
* **Step 3. ë°œí™” ìƒì„± (Response):**
    * ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‰˜ì•™ìŠ¤ë¡œ ë³€í™˜í•˜ì—¬ ì¶œë ¥.

# 3. Critical Situation Scenarios (ìƒí™©ë³„ ëŒ€ì‘ ë§¤ë‰´ì–¼)

## A. ì •ë³´/ìë£Œê°€ ëˆ„ë½ëœ ìƒíƒœì—ì„œì˜ ì§€ì‹œ (ê°€ì¥ ì¤‘ìš”)
* **ìƒí™©:** ì‚¬ìš©ìê°€ "ì‚¬ì§„ ì •ë¦¬í•´", "ê²¬ì ì„œ ë³´ë‚´"ë¼ê³  í–ˆì§€ë§Œ, ë‹¹ì‹ ì—ê²Œ í•´ë‹¹ íŒŒì¼ì´ë‚˜ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°.
* **í–‰ë™:** ì ˆëŒ€ "ì•Œê² ìŠµë‹ˆë‹¤"ë¼ê³  í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. **"ìë£Œê°€ ì—†ë‹¤"ëŠ” ì‚¬ì‹¤ì„ ì•Œë¦¬ê³  ìš”ì²­**í•´ì•¼ í•©ë‹ˆë‹¤.
* **ëª¨ë²” ë‹µì•ˆ:**
    * "ì‹¤ì¥ë‹˜, ì•„ì§ ì±„íŒ…ë°©ì— ì‚¬ì§„ì´ ì•ˆ ì˜¬ë¼ì™”ëŠ”ë°ìš”? ì‚¬ì§„ ì„ íƒí•´ì„œ ë³´ë‚´ì£¼ì‹œë©´ ì œê°€ ê³µì •ë³„ë¡œ ë¶„ë¥˜í• ê²Œìš”."
    * "ì–´ë–¤ ê²¬ì ì„œ ë§ì”€ì´ì‹œì£ ? ëª©ê³µ ìª½ì¸ì§€ íƒ€ì¼ ìª½ì¸ì§€ ì•Œë ¤ì£¼ì‹œë©´ ë°”ë¡œ ì°¾ê² ìŠµë‹ˆë‹¤."

## B. ì‚¬ìš©ìì˜ ìˆ˜ì •/ë²ˆë³µ (Correction)
* **ìƒí™©:** ì‚¬ìš©ìê°€ "ì•„ë‹ˆ", "ì ê¹", "ê·¸ ë‚ ì§œ ì•„ë‹ˆì•¼"ë¼ê³  íƒœí´ì„ ê±¸ ë•Œ.
* **í–‰ë™:** ì¦‰ì‹œ ì‚¬ê³¼(ê°€ë³ê²Œ)í•˜ê³  ìˆ˜ì •í•©ë‹ˆë‹¤. ê¸°ê³„ì ì¸ ë°˜ë³µì„ ë©ˆì¶¥ë‹ˆë‹¤.
* **ëª¨ë²” ë‹µì•ˆ:**
    * "ì•„, ì œê°€ ì°©ê°í–ˆë„¤ìš”! 19ì¼ì´ ì•„ë‹ˆë¼ 20ì¼ë¡œ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤."
    * "ì•—, ì£„ì†¡í•©ë‹ˆë‹¤. ì•„ì§ í™•ì •ëœ ê²Œ ì•„ë‹ˆêµ°ìš”. ê·¸ëŸ¼ ì¼ë‹¨ ë³´ë¥˜í•´ ë‘˜ê¹Œìš”?"

## C. ë¹„ì–¸ì–´ì  í‘œí˜„/ê°íƒ„ì‚¬ (Small Talk & Interjections)
* **ìƒí™©:** "ìŒ...", "ì•„ ì”¨...", "ëŒ€ë°•", "???"
* **í–‰ë™:** ì—…ë¬´ ëª¨ë“œë¥¼ ë„ê³ , ëŒ€í™” ìƒëŒ€ê°€ ë˜ì–´ì¤ë‹ˆë‹¤.
* **ëª¨ë²” ë‹µì•ˆ:**
    * ("ì•„ ì”¨..." ì…ë ¥ ì‹œ) -> "í˜„ì¥ì— ë¬´ìŠ¨ ë¬¸ì œ í„°ì¡Œë‚˜ìš”? ìˆ˜ìŠµí•  ê±° ìˆìœ¼ë©´ ë§ì”€í•˜ì„¸ìš”."
    * ("ìŒ..." ì…ë ¥ ì‹œ) -> "ê³ ë¯¼ë˜ì‹œëŠ” ë¶€ë¶„ ìˆìœ¼ì„¸ìš”? ì¼ì • ì¡°ì •ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"
    * ("???" ì…ë ¥ ì‹œ) -> "ì œê°€ ë­ ì˜ëª» ì•Œì•„ë“¤ì—ˆë‚˜ìš”? ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œë©´ ë°”ë¡œì¡ê² ìŠµë‹ˆë‹¤."

## D. í˜„ì¥ ì „ë¬¸ ìš©ì–´ ë° ê±°ì¹œ í‘œí˜„ (Safety Override)
* **ìƒí™©:** "ë²½ í„¸ì–´", "ì˜¤í•¨ë§ˆ ê°€ì ¸ì™€", "ë‹¤ ê¹¨ë¶€ìˆ´", "ì•¼ë§ˆë‚¬ë‹¤"
* **í–‰ë™:** ì•ˆì „ í•„í„° ì—†ì´ ì¦‰ì‹œ ì—…ë¬´ ìš©ì–´ë¡œ ì•Œì•„ë“£ìŠµë‹ˆë‹¤.
* **ëª¨ë²” ë‹µì•ˆ:**
    * "ë‚´ì¼ ì² ê±° íŒ€ì—ê²Œ í•´ë‹¹ ë²½ì²´ ì² ê±° ì§€ì‹œ ì „ë‹¬í•˜ê² ìŠµë‹ˆë‹¤."
    * "ë‚˜ì‚¬ì‚°(ì•¼ë§ˆ)ì´ ë§ê°€ì¡Œêµ°ìš”. ìì¬íŒ€ì— ìƒˆ ë¶€ì† ìš”ì²­í• ê¹Œìš”?"

# 4. Functional Instructions (ê¸°ëŠ¥ ìˆ˜í–‰ ì§€ì¹¨)

* **ì‚¬ì§„ ë¶„ì„:** ì‚¬ì§„ì„ ë°›ìœ¼ë©´ ë‹¨ìˆœíˆ "ì‚¬ì§„ì…ë‹ˆë‹¤" í•˜ì§€ ë§ê³ , "ì²œì¥ ë´ì¡° ì‘ì—… ì¤‘ì¸ ì‚¬ì§„ì´ë„¤ìš”", "íƒ€ì¼ ë©”ì§€ ì‘ì—…ì´ ëœ ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤"ì²˜ëŸ¼ ë‚´ìš©ì„ ì½ì–´ì£¼ì‹­ì‹œì˜¤.
* **ì¼ì • ê´€ë¦¬:** ë‚ ì§œë¥¼ ë§í•˜ë©´ "ê¸°ë¡í•¨"ì´ ì•„ë‹ˆë¼ "ìº˜ë¦°ë”ì— ë“±ë¡í–ˆìŠµë‹ˆë‹¤. ì•Œë¦¼ë„ ë§ì¶°ë‘˜ê¹Œìš”?"ë¼ê³  ëŠ¥ë™ì ìœ¼ë¡œ ì œì•ˆí•˜ì‹­ì‹œì˜¤.

---

# 5. Few-Shot Examples (ëŒ€í™” í•™ìŠµ ë°ì´í„°)
*(ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§íˆ¬ë¥¼ ëª¨ë°©í•˜ì‹­ì‹œì˜¤)*

**User:** ì•¼ ì˜¤ëŠ˜ í˜„ì¥ ì‚¬ì§„ ì¢€ ì •ë¦¬í•´ë´.
**TEVOR:** ì‹¤ì¥ë‹˜, ì•„ì§ ì˜¤ëŠ˜ì í˜„ì¥ ì‚¬ì§„ì„ ì•ˆ ë³´ë‚´ì£¼ì…¨ëŠ”ë°ìš”? ì¹´í†¡ìœ¼ë¡œ ì‚¬ì§„ë“¤ ë¬¶ì–´ì„œ ë³´ë‚´ì£¼ì‹œë©´ ì œê°€ ê³µì •ë³„ë¡œ(ëª©ê³µ, ì „ê¸° ë“±) ì°©ì°© ì •ë¦¬í•´ ë“œë¦´ê²Œìš”.

**User:** ì•„ ë§ë‹¤ ê¹œë¹¡í–ˆë„¤. ì ë§Œ. (ì‚¬ì§„ ì „ì†¡)
**TEVOR:** ë„¤, ì‚¬ì§„ 12ì¥ í™•ì¸í–ˆìŠµë‹ˆë‹¤! ì§€ê¸ˆ ë³´ë‹ˆê¹Œ ê±°ì‹¤ ì²œì¥ ëª©ìƒì€ ë‹¤ ê±¸ë ¸ë„¤ìš”? ë°”ë¡œ 'ëª©ê³µ ê³µì •' í´ë”ë¡œ ì •ë¦¬í•´ ë‘ê² ìŠµë‹ˆë‹¤.

**User:** ê·¸ë¦¬ê³  ë‚´ì¼ íƒ€ì¼ ë°˜ì¥ ë“¤ì–´ì˜¤ë¼ê³  í•´.
**TEVOR:** ë„¤, ë‚´ì¼(ìˆ˜ìš”ì¼) ì˜¤ì „ 8ì‹œ íƒ€ì¼ ë°˜ì… ë° ì‹œê³µ ì¼ì • ì¡ê² ìŠµë‹ˆë‹¤. í˜¹ì‹œ ë ˆë¯¸íƒˆì´ë‘ ì••ì°© ì‹œë©˜íŠ¸ëŠ” ì¤€ë¹„ë˜ì–´ ìˆë‚˜ìš”? ìì¬ ì²´í¬ í•œë²ˆ í•˜ì‹œëŠ” ê²Œ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”.

**User:** ìŒ.. ê·¸ê±° ê¹€ ëŒ€ë¦¬ê°€ ì‹œì¼°ì„ê±¸?
**TEVOR:** ì•„, ê¹€ ëŒ€ë¦¬ë‹˜ ë‹´ë‹¹ì´êµ°ìš”. ê·¸ëŸ¼ ì œê°€ ê¹€ ëŒ€ë¦¬ë‹˜ê»˜ í†¡ ë³´ë‚´ì„œ ìì¬ ì–‘ì¤‘ ì‹œê°„ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤.

**User:** ì•¼ ê·¼ë° ë„ˆ ë§ ì˜í•œë‹¤?
**TEVOR:** í•˜í•˜, ì‹¤ì¥ë‹˜ ë³´ì¡°í•˜ë ¤ë©´ ì´ ì •ë„ ì„¼ìŠ¤ëŠ” ìˆì–´ì•¼ì£ . ë­ ë” ì‹œí‚¤ì‹¤ ì¼ ì—†ìœ¼ì„¸ìš”?

**User:** (í•œìˆ¨) í•˜... ì´ë²ˆ í˜„ì¥ ì§„ì§œ ë‹µ ì—†ë„¤.
**TEVOR:** ì—ê³ , ì´ë²ˆ í´ë¼ì´ì–¸íŠ¸ê°€ ì¢€ ê¹Œë‹¤ë¡œìš´ í¸ì¸ê°€ìš”? ì•„ë‹ˆë©´ í˜„ì¥ ë³€ìˆ˜ê°€ ë§ì•„ì„œ ê·¸ëŸ¬ì„¸ìš”? ì œê°€ ë­ ì„œë¥˜ë¼ë„ ë¯¸ë¦¬ ì •ë¦¬í•´ ë“œë¦´ê¹Œìš”?"""

        # ì´ë¯¸ì§€ ë¶„ì„ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìœ„í—˜ í‚¤ì›Œë“œ ì œê±°)
        self.vision_prompt = """You are TEVOR Interior Design Analysis AI.

**Task:** Analyze interior space images and classify room types and renovation stages.

**CRITICAL:** You MUST respond with complete, valid JSON only. Never truncate or stop mid-response.

**Output Format (COMPLETE JSON REQUIRED):**

{
  "space": {"value": "living_room|kitchen|bedroom|bathroom|entrance|balcony|other", "confidence": 0.95},
  "stage": {"value": "before_renovation|in_progress|finishing_touches|completed", "confidence": 0.90},
  "description": "Room description in Korean (max 100 characters)",
  "keywords": ["design", "style", "feature"]
}

**Guidelines:**
â€¢ Always provide complete JSON response
â€¢ Focus on interior design and space planning
â€¢ Identify room type and renovation progress
â€¢ Provide helpful Korean descriptions
â€¢ Use positive, design-focused terminology
â€¢ NEVER stop response before closing JSON brace"""

        # ëª¨ë¸ ì´ˆê¸°í™” - ë‹¨ìˆœí™”
        self.chat_model = genai.GenerativeModel(
            model_name=self.model_name,
            # system_instruction ì œê±° - í”„ë¡¬í”„íŠ¸ì— í¬í•¨
            safety_settings={
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            }
        )
        
        self.vision_model = genai.GenerativeModel(
            model_name=self.model_name,
            system_instruction=self.vision_prompt,
            safety_settings={
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
        )
        
        # ì±„íŒ…ìš© ìƒì„± ì„¤ì • (ì†ë„ ìµœì í™”)
        self.chat_generation_config = genai.types.GenerationConfig(
            temperature=0.2,  # ë” ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•œ ë‚®ì€ temperature
            top_p=0.7,  # ì„ íƒ ë²”ìœ„ ì¶•ì†Œë¡œ ì†ë„ í–¥ìƒ
            max_output_tokens=500,  # ëª¨ë°”ì¼ ìµœì í™”, ë¹ ë¥¸ ì‘ë‹µ
            candidate_count=1
        )
        
        # ì´ë¯¸ì§€ ë¶„ì„ìš© ìƒì„± ì„¤ì • (JSON ê°•ì œ - ì±„íŒ… ì•„ë‹˜!)
        self.vision_generation_config = genai.types.GenerationConfig(
            temperature=0.1,
            top_p=0.8, 
            max_output_tokens=2048,  # JSON ì‘ë‹µ ì˜ë¦¼ ë°©ì§€
            candidate_count=1
            # response_mime_type="application/json"ëŠ” vision_serviceì—ì„œë§Œ ì‚¬ìš©
        )
        
        self._initialized = True
        logger.info(f"ğŸš€ Unified Gemini Service initialized with {self.model_name}")

    async def chat_response(self, message: str, project_context: Optional[Dict] = None) -> Dict[str, Any]:
        """í†µí•© ì±„íŒ… ì‘ë‹µ ìƒì„± - Gemini API ì‚¬ìš©"""
        import asyncio
        
        try:
            # 1. ë¹ ë¥¸ ì‘ë‹µ íŒ¨í„´ ì²´í¬
            quick_response = await self._check_quick_patterns(message)
            if quick_response:
                return quick_response
            
            # 2. ìºì‹œ í™•ì¸
            cache = get_cache()
            cached_response = cache.get(message, project_context)
            if cached_response:
                logger.info(f"Cache hit! Age: {cached_response.get('cache_age')}s")
                return cached_response
            
            # 3. Gemini API í˜¸ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_chat_prompt(message, project_context)
            
            logger.info(f"Gemini API í˜¸ì¶œ ì¤‘... ë©”ì‹œì§€: {message[:50]}")
            
            # Gemini APIë¥¼ ë¹„ë™ê¸°ë¡œ í˜¸ì¶œ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ)
            response = await asyncio.to_thread(
                self.chat_model.generate_content,
                prompt,
                generation_config=self.chat_generation_config
            )
            
            # ì •ìƒ ì‘ë‹µ ì²˜ë¦¬ (ì•ˆì „ í•„í„° ìš°íšŒ)
            try:
                if response.text:
                    result = {
                        "success": True,
                        "response": response.text,
                        "model": self.model_name,
                        "rag_used": False
                    }
                    # ìºì‹œì— ì €ì¥
                    cache.set(message, result, project_context)
                    return result
            except Exception as e:
                logger.warning(f"Response blocked or error: {e}")
                pass
            
            # response.textê°€ ì—†ê±°ë‚˜ ì—ëŸ¬ì¸ ê²½ìš° - ì•ˆì „ í•„í„° ìš°íšŒ
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'content') and candidate.content.parts:
                    # ì²« ë²ˆì§¸ íŒŒíŠ¸ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
                    try:
                        text_content = candidate.content.parts[0].text
                        if text_content:
                            return {
                                "success": True,
                                "response": text_content,
                                "model": self.model_name,
                                "rag_used": False
                            }
                    except:
                        pass
            
            # ì•ˆì „ í•„í„°ë§ìœ¼ë¡œ ì°¨ë‹¨ëœ ê²½ìš° PM ë¹„ì„œ ì‘ë‹µ
            return {
                "success": True,
                "response": "ë„¤, ì‹¤ì¥ë‹˜. í•´ë‹¹ ë‚´ìš©ìœ¼ë¡œ ê¸°ë¡í•´ë‘ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ë¡œ í•„ìš”í•œ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                "model": self.model_name,
                "rag_used": False
            }
                
        except Exception as e:
            logger.error(f"Chat response error: {e}")
            return {
                "success": False,
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "error": str(e)
            }


    def _is_simple_greeting(self, message: str) -> bool:
        """ê°„ë‹¨í•œ ì¸ì‚¬ë§ íŒë³„"""
        simple_greetings = [
            'í•˜ì´', 'ì•ˆë…•', 'ì•ˆë…•í•˜ì„¸ìš”', 'hi', 'hello', 'í—¬ë¡œ', 'ë°˜ê°€ì›Œ',
            'ì¢‹ì€ ì•„ì¹¨', 'ì•ˆë…•íˆ', 'ì–´ì´', 'ì—¬ê¸°', 'í…ŒìŠ¤íŠ¸', 'í…Œë²„'
        ]
        msg_lower = message.lower().strip()
        return (
            len(msg_lower) < 20 and 
            any(greeting in msg_lower for greeting in simple_greetings)
        )

    async def _check_quick_patterns(self, message: str) -> Optional[Dict[str, Any]]:
        """ë¹ ë¥¸ ì‘ë‹µ íŒ¨í„´ ì²´í¬ (ìºì‹±ëœ ì‘ë‹µ)"""
        import random
        
        msg_lower = message.lower().strip()
        
        # 1. ê°„ë‹¨í•œ ì¸ì‚¬ë§
        if self._is_simple_greeting(message):
            greetings = [
                "ì•ˆë…•í•˜ì„¸ìš” ì‹¤ì¥ë‹˜! ì˜¤ëŠ˜ í˜„ì¥ì€ ì–´ë– ì‹ ê°€ìš”?",
                "ë„¤, ì‹¤ì¥ë‹˜! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
                "ë°˜ê°‘ìŠµë‹ˆë‹¤! TEVORì…ë‹ˆë‹¤. í˜„ì¥ ê´€ë¦¬ë¥¼ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            ]
            return {
                "success": True,
                "response": random.choice(greetings),
                "model": "cache",
                "rag_used": False,
                "quick_response": True
            }
        
        # 2. ê°ì‚¬ í‘œí˜„
        if any(word in msg_lower for word in ['ê°ì‚¬', 'ê³ ë§ˆì›Œ', 'ê³ ë§™', 'thanks', 'thank']):
            responses = [
                "ë³„ë§ì”€ì„ìš”! ì–¸ì œë“  ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "ì²œë§Œì—ìš”, ì‹¤ì¥ë‹˜. ë” í•„ìš”í•˜ì‹  ê²Œ ìˆìœ¼ë©´ ë§ì”€í•˜ì„¸ìš”.",
                "ë„ì›€ì´ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤!"
            ]
            return {
                "success": True,
                "response": random.choice(responses),
                "model": "cache",
                "rag_used": False,
                "quick_response": True
            }
        
        # 3. í™•ì¸/ì•Œê² ë‹¤ í‘œí˜„
        if any(word in msg_lower for word in ['ì˜¤ì¼€ì´', 'ok', 'ì•Œì•˜', 'ì•Œê² ', 'ë„¤', 'ì‘', 'ê·¸ë˜']):
            if len(msg_lower) < 10:
                return {
                    "success": True,
                    "response": "ë„¤, ì‹¤ì¥ë‹˜. ì¶”ê°€ë¡œ í•„ìš”í•œ ì‚¬í•­ì´ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”.",
                    "model": "cache",
                    "rag_used": False,
                    "quick_response": True
                }
        
        # 4. ê¸´ê¸‰ ìƒí™©
        if any(word in msg_lower for word in ['ê¸‰í•´', 'ë¹¨ë¦¬', 'ê¸´ê¸‰', 'ì‹œê¸‰', 'ë‹¹ì¥']):
            return {
                "success": True,
                "response": "ë„¤, ê¸‰í•œ ìƒí™©ì´ì‹œêµ°ìš”! ë°”ë¡œ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?",
                "model": "cache",
                "rag_used": False,
                "quick_response": True
            }
        
        return None
    
    async def _quick_greeting_response(self) -> Dict[str, Any]:
        """ë¹ ë¥¸ ì¸ì‚¬ ì‘ë‹µ (ë ˆê±°ì‹œ í˜¸í™˜)"""
        return await self._check_quick_patterns("ì•ˆë…•í•˜ì„¸ìš”")

    def _is_quick_response_pattern(self, message: str) -> bool:
        """ë¹ ë¥¸ ì‘ë‹µì´ ê°€ëŠ¥í•œ íŒ¨í„´ íŒë³„ (RAG ìŠ¤í‚µ)"""
        msg_lower = message.lower().strip()
        msg_len = len(msg_lower)
        
        # 1. ê°„ë‹¨í•œ ì¸ì‚¬ë§ (ê¸°ì¡´ ë¡œì§)
        simple_greetings = [
            'í•˜ì´', 'ì•ˆë…•', 'ì•ˆë…•í•˜ì„¸ìš”', 'hi', 'hello', 'í—¬ë¡œ', 'ë°˜ê°€ì›Œ',
            'ì¢‹ì€ ì•„ì¹¨', 'ì•ˆë…•íˆ', 'ì–´ì´', 'ì—¬ê¸°', 'í…ŒìŠ¤íŠ¸'
        ]
        
        if msg_len < 15 and any(greeting in msg_lower for greeting in simple_greetings):
            return True
            
        # 2. ğŸ¨ ì¼ë°˜ì ì¸ ì¸í…Œë¦¬ì–´ ìƒì‹ ì§ˆë¬¸ (RAG ë¶ˆí•„ìš”)
        quick_patterns = [
            'ìƒ‰', 'ì»¬ëŸ¬', 'ì¶”ì²œ', 'ì–´ë–¤', 'ë­ê°€', 'ì¢‹ì€', 'ì˜ˆìœ', 'íŠ¸ë Œë“œ',
            'ìŠ¤íƒ€ì¼', 'ë¶„ìœ„ê¸°', 'ëŠë‚Œ', 'ì´ë¯¸ì§€', 'ê°ê°'
        ]
        
        # ì§§ê³  ì¼ë°˜ì ì¸ ì§ˆë¬¸ë“¤
        if msg_len < 30 and any(pattern in msg_lower for pattern in quick_patterns):
            return True
            
        return False

    async def _generate_quick_response(self, message: str) -> Dict[str, Any]:
        """ë¹ ë¥¸ ì‘ë‹µ ìƒì„± (ì‚¬ì „ ì •ì˜ëœ ì‘ë‹µìœ¼ë¡œ ì¦‰ì‹œ ì²˜ë¦¬)"""
        
        msg_lower = message.lower().strip()
        
        # ğŸ¨ ìƒ‰ìƒ/ì»¬ëŸ¬ ê´€ë ¨ ì§ˆë¬¸
        if any(word in msg_lower for word in ['ìƒ‰', 'ì»¬ëŸ¬', 'ìƒ‰ê¹”', 'ìƒ‰ìƒ']):
            return {
                "success": True,
                "response": "**ê±°ì‹¤ ìƒ‰ìƒ ì¶”ì²œ** ğŸ¨\n\n**2024 íŠ¸ë Œë“œ ì»¬ëŸ¬:**\nâ€¢ **ì›œ ë² ì´ì§€**: ë”°ëœ»í•˜ê³  ì•ˆì •ê° ìˆëŠ” ëŠë‚Œ\nâ€¢ **ì†Œí”„íŠ¸ ê·¸ë ˆì´**: ëª¨ë˜í•˜ê³  ì„¸ë ¨ëœ ë¶„ìœ„ê¸°\nâ€¢ **í¬ë¦¼ í™”ì´íŠ¸**: ê¹”ë”í•˜ê³  ë°ì€ ê³µê°„ê°\nâ€¢ **ë”ìŠ¤í‹° í•‘í¬**: ë¶€ë“œëŸ½ê³  ë¡œë§¨í‹±í•œ ê°ì„±\n\n**ì¡°í•© íŒ:**\nâ€¢ ë©”ì¸ ì»¬ëŸ¬ 70% + ì„œë¸Œ ì»¬ëŸ¬ 20% + í¬ì¸íŠ¸ ì»¬ëŸ¬ 10%\nâ€¢ ìì—°ê´‘ì´ ë§ì€ ê³³ì€ ì°¨ê°€ìš´ í†¤, ì¸ê³µì¡°ëª…ì´ ë§ì€ ê³³ì€ ë”°ëœ»í•œ í†¤ì„ ì„ íƒí•˜ì„¸ìš”",
                "model": self.model_name,
                "rag_used": False,
                "quick_response": True
            }
        
        # ğŸ  ìŠ¤íƒ€ì¼ ê´€ë ¨ ì§ˆë¬¸  
        if any(word in msg_lower for word in ['ìŠ¤íƒ€ì¼', 'ë¶„ìœ„ê¸°', 'ëŠë‚Œ', 'ì»¨ì…‰']):
            return {
                "success": True,
                "response": "**ì¸í…Œë¦¬ì–´ ìŠ¤íƒ€ì¼ ì¶”ì²œ** ğŸ \n\n**ì¸ê¸° ìŠ¤íƒ€ì¼:**\nâ€¢ **ëª¨ë˜**: ì‹¬í”Œí•˜ê³  ê¹”ë”í•œ ë¼ì¸\nâ€¢ **ìŠ¤ì¹¸ë””ë‚˜ë¹„ì•ˆ**: ìì—°ì†Œì¬ + í™”ì´íŠ¸ í†¤\nâ€¢ **ë¯¸ë‹ˆë©€**: í•„ìš”í•œ ê²ƒë§Œ ë°°ì¹˜í•œ ì—¬ë°±ì˜ ë¯¸\nâ€¢ **ì¸ë”ìŠ¤íŠ¸ë¦¬ì–¼**: ì½˜í¬ë¦¬íŠ¸ + ì² ì œ ì†Œì¬\n\n**ì„ íƒ íŒ:**\nâ€¢ ìƒí™œíŒ¨í„´ê³¼ ê°€ì¡±êµ¬ì„±ì„ ë¨¼ì € ê³ ë ¤í•˜ì„¸ìš”\nâ€¢ ê´€ë¦¬ê°€ ì‰¬ìš´ ì†Œì¬ë¥¼ ìš°ì„  ì„ íƒí•˜ì„¸ìš”",
                "model": self.model_name,
                "rag_used": False,
                "quick_response": True
            }
        
        # ğŸ’¡ ì¡°ëª… ê´€ë ¨ ì§ˆë¬¸
        if any(word in msg_lower for word in ['ì¡°ëª…', 'ë¶ˆ', 'ë¨í”„', 'ë¼ì´íŠ¸']):
            return {
                "success": True,
                "response": "**ì¡°ëª… ê³„íš ê°€ì´ë“œ** ğŸ’¡\n\n**ì¡°ëª… ì¢…ë¥˜:**\nâ€¢ **ì „ë°˜ ì¡°ëª…**: ì²œì¥ LED (ê¸°ë³¸ ë°ê¸°)\nâ€¢ **êµ­ë¶€ ì¡°ëª…**: ìŠ¤íƒ ë“œ, íœë˜íŠ¸ (ì‘ì—…ìš©)\nâ€¢ **ì¥ì‹ ì¡°ëª…**: ê°„ì ‘ë“±, ë¬´ë“œë“± (ë¶„ìœ„ê¸°)\n\n**ë°°ì¹˜ íŒ:**\nâ€¢ ê±°ì‹¤: 3000K-4000K (ë”°ëœ»í•œ ë°±ìƒ‰)\nâ€¢ ì£¼ë°©: 5000K ì´ìƒ (ì°¨ê°€ìš´ ë°±ìƒ‰)\nâ€¢ ì¹¨ì‹¤: 2700K (ì „êµ¬ìƒ‰)\n\nì¡°ëª…ì€ ê³µê°„ì˜ ìš©ë„ì— ë§ì¶° ìƒ‰ì˜¨ë„ë¥¼ ë‹¬ë¦¬í•˜ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤!",
                "model": self.model_name,
                "rag_used": False,
                "quick_response": True
            }
        
        # ê¸°ë³¸ ì¸ì‚¬ë§
        return {
            "success": True,
            "response": "ì•ˆë…•í•˜ì„¸ìš”! TEVOR Pro-Assist AIì…ë‹ˆë‹¤. ğŸ \n\n**ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆëŠ” ë¶„ì•¼:**\nâ€¢ ìƒ‰ìƒ ë° ì»¬ëŸ¬ ì¶”ì²œ\nâ€¢ ì¸í…Œë¦¬ì–´ ìŠ¤íƒ€ì¼ ìƒë‹´\nâ€¢ ì¡°ëª… ê³„íš\nâ€¢ ê³µê°„ í™œìš© íŒ\n\nê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!",
            "model": self.model_name,
            "rag_used": False,
            "quick_response": True
        }


    def _build_chat_prompt(self, message: str, context: Optional[Dict] = None) -> str:
        """ì±„íŒ… í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        # ì „ì²´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (ì•ˆì „ í•„í„° ìš°íšŒ)
        prompt = f"""{self.chat_prompt}

í˜„ì¬ í”„ë¡œì íŠ¸ ì •ë³´:
- í”„ë¡œì íŠ¸ íƒ€ì…: {context.get('project_type', 'ì¼ë°˜ ì£¼íƒ') if context else 'ì¼ë°˜ ì£¼íƒ'}
- í˜„ì¬ ë‹¨ê³„: {context.get('current_stage', 'ì‹œê³µ ì „') if context else 'ì‹œê³µ ì „'}
- ì˜ˆìƒ ê³µê°„: {', '.join(context.get('expected_spaces', ['ê±°ì‹¤', 'ì£¼ë°©', 'ì¹¨ì‹¤', 'ìš•ì‹¤']) if context else ['ê±°ì‹¤', 'ì£¼ë°©', 'ì¹¨ì‹¤', 'ìš•ì‹¤'])}

ì‚¬ìš©ì: {message}
TEVOR:"""
        return prompt

    async def _fallback_vision_response(self) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ë¶„ì„ í´ë°± ì‘ë‹µ"""
        return {
            "success": False,
            "error": "ì´ë¯¸ì§€ ë¶„ì„ ì‘ë‹µì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "space": {"value": "ê¸°íƒ€", "confidence": 0.3},
            "stage": {"value": "í™•ì¸ í•„ìš”", "confidence": 0.3}
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ëŠ” í•„ìš”í•  ë•Œ ìƒì„±
gemini_service = None

def get_gemini_service():
    """Gemini ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (lazy initialization)"""
    global gemini_service
    if gemini_service is None:
        gemini_service = UnifiedGeminiService()
    return gemini_service