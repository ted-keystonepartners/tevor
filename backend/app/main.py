import os
import time
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from contextlib import asynccontextmanager
from dotenv import load_dotenv

from app.database import init_db
from app.api import projects, chat, images, chat_stream
# GPT Service ì œê±°ë¨ - Geminië¡œ í†µí•©

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì„œë²„ ì‹œì‘ì‹œ: ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    print("ğŸš€ TEVOR Backend ì‹œì‘ ì¤‘...")
    print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”...")
    await init_db()
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸ (OpenAI APIë§Œ ì‚¬ìš©)
    openai_key = os.getenv("OPENAI_API_KEY")
    
    if not openai_key:
        print("âš ï¸  ê²½ê³ : OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("   ì±„íŒ… ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ .env íŒŒì¼ì„ ìƒì„±í•˜ê³  OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")
    else:
        print("âœ… OpenAI API Key í™•ì¸ë¨")
        
        # API í‚¤ ìœ íš¨ì„± ê°„ë‹¨ ê²€ì¦
        if len(openai_key.strip()) < 20:
            print("âš ï¸ OpenAI API í‚¤ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìœ íš¨í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif not openai_key.startswith("sk-"):
            print("âš ï¸ OpenAI API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ìŠ¤í† ë¦¬ì§€ í´ë” ìƒì„±
    storage_path = os.getenv("STORAGE_PATH", "storage/projects")
    os.makedirs(storage_path, exist_ok=True)
    os.makedirs("db", exist_ok=True)
    
    print(f"ğŸ“ ìŠ¤í† ë¦¬ì§€ ê²½ë¡œ: {os.path.abspath(storage_path)}")
    print("ğŸ¯ TEVOR Backend ì¤€ë¹„ ì™„ë£Œ!")
    print("ğŸŒ ì„œë²„ ì£¼ì†Œ: http://localhost:8000")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:8000/docs")
    
    yield
    
    # ì„œë²„ ì¢…ë£Œì‹œ
    print("ğŸ›‘ TEVOR Backend ì¢…ë£Œ ì¤‘...")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="TEVOR API",
    description="ì¸í…Œë¦¬ì–´ ì‹œê³µ AI ì»¨ì‹œì–´ì§€ ë°±ì—”ë“œ API",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì • (í”„ë¡œë•ì…˜ ì§€ì›)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000", 
        "http://127.0.0.1:3000",
        "https://tevor.vercel.app",  # Vercel ê¸°ë³¸ ë„ë©”ì¸
        "https://tevor-*.vercel.app",  # Vercel í”„ë¦¬ë·° ë„ë©”ì¸
        "https://*.vercel.app",  # ëª¨ë“  Vercel ë„ë©”ì¸ (ê°œë°œ ì¤‘)
        # ì»¤ìŠ¤í…€ ë„ë©”ì¸ ì¶”ê°€ ì‹œ ì—¬ê¸°ì— ì¶”ê°€
    ],
    allow_credentials=True,  # ì¿ í‚¤/ì¸ì¦ ì§€ì›
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],  # OPTIONS ì¶”ê°€
    allow_headers=[
        "Content-Type", 
        "Authorization",
        "Accept",
        "Origin",
        "X-Requested-With"
    ],
)

# ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì • (ì•„ì¹´ì´ë¸Œ ì´ë¯¸ì§€)
archive_path = "archive"
if os.path.exists(archive_path):
    app.mount("/archive", StaticFiles(directory=archive_path), name="archive")

# ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì • (ìŠ¤í† ë¦¬ì§€ ì´ë¯¸ì§€ - temp ë° ì¼ë°˜ íŒŒì¼)
storage_base_path = "storage"  # storage ì „ì²´ ë””ë ‰í† ë¦¬ë¥¼ ì„œë¹™
if os.path.exists(storage_base_path):
    app.mount("/storage", StaticFiles(directory=storage_base_path), name="storage")

# ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì • (ì±„íŒ… ì´ë¯¸ì§€)
static_images_path = "static/images"
os.makedirs(static_images_path, exist_ok=True)
app.mount("/static", StaticFiles(directory="static"), name="static")

# API ë¼ìš°í„° ë“±ë¡
app.include_router(projects.router)
app.include_router(chat.router)
app.include_router(chat_stream.router)  # ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ë¼ìš°í„° ì¶”ê°€
app.include_router(images.router)

# API ë¼ìš°í„° (ë¦¬íŒ©í† ë§ ì™„ë£Œ)

# í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    return {
        "service": "TEVOR API",
        "version": "1.0.0",
        "status": "healthy",
        "message": "ì¸í…Œë¦¬ì–´ ì‹œê³µ AI ì»¨ì‹œì–´ì§€ ë°±ì—”ë“œê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
        "docs": "/docs"
    }

@app.get("/health")
async def health_check():
    try:
        # ê¸°ë³¸ ìƒíƒœ ì²´í¬
        health_status = {
            "status": "healthy",
            "database": "ok",
            "storage": "ok",
            "ai_service": "unknown"
        }
        
        # ìŠ¤í† ë¦¬ì§€ í´ë” ì²´í¬
        storage_path = os.getenv("STORAGE_PATH", "storage/projects")
        if not os.path.exists(storage_path):
            health_status["storage"] = "error"
            health_status["status"] = "degraded"
        
        # OpenAI API í‚¤ ì²´í¬
        openai_key = os.getenv("OPENAI_API_KEY")
        
        if openai_key:
            health_status["ai_service"] = "configured"
        else:
            health_status["ai_service"] = "not_configured"
            health_status["status"] = "degraded"
        
        return health_status
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Health check failed: {str(e)}")

# í™˜ê²½ ì •ë³´ ì—”ë“œí¬ì¸íŠ¸ (ê°œë°œìš©)
@app.get("/env-info")
async def env_info():
    openai_configured = bool(os.getenv("OPENAI_API_KEY"))
    
    return {
        "storage_path": os.path.abspath(os.getenv("STORAGE_PATH", "storage/projects")),
        "database_url": os.getenv("DATABASE_URL", "sqlite:///db/tevor.db"),
        "openai_configured": openai_configured,
        "ai_service": "OpenAI GPT" if openai_configured else "Not configured",
        "python_version": os.sys.version,
        "working_directory": os.getcwd()
    }

# ìºì‹œ í†µê³„ ì—”ë“œí¬ì¸íŠ¸ (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ìš©)
@app.get("/cache-stats")
async def cache_stats():
    return {
        "service": "TEVOR Cache Statistics",
        "timestamp": time.time(),
        "gemini_service": "active",
        "archive_service": "active",
        "status": "healthy"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )